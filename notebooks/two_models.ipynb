{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import torch\n",
    "from modconn import curves\n",
    "from datasets import get_model_class\n",
    "from datasets.tabular import TabularModel, TabularModelCurve, TabularModelPerturb\n",
    "from style import bold\n",
    "from similarity import get_top_k, average_pairwise_score, top_k_sa, average_ground_truth_score, ground_truth_score\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from util import get_weight_diff, get_weight_norm, linear_weight_interpolation\n",
    "from align import compute_model_alignment, align_models, align_tabular\n",
    "from fusion import align_networks, load_aligned_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'heloc'  # or 'heloc'\n",
    "n_models = 1000\n",
    "random_sources = ['rs', 'loo']\n",
    "\n",
    "# Random source\n",
    "random_source = random_sources[0]\n",
    "print(bold(\"Random source:\"), random_source)\n",
    "\n",
    "optim = 'adam'\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "lr = 0.0004\n",
    "# optim = 'sgd'\n",
    "# epochs = 20\n",
    "# lr = 0.1\n",
    "# batch_size = 64\n",
    "dropout = 0\n",
    "directory = f'models/{name}/{random_source}/{optim}_epochs{epochs}_lr{lr}_batch{batch_size}_dropout{dropout}'\n",
    "print(bold(\"Directory:\"), directory)\n",
    "\n",
    "trainset, testset = datasets.load_dataset(name)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
    "X_train, y_train = trainset.data.numpy(), trainset.labels.numpy()\n",
    "X_test, y_test = testset.data.numpy(), testset.labels.numpy()\n",
    "n_inputs, n_features = X_test.shape\n",
    "model_args = [n_features, datasets.tabular.layers[name]]\n",
    "layer_str = 'network.0.weight'\n",
    "\n",
    "def load_model(idx):\n",
    "    model_class = get_model_class(name)\n",
    "    model = model_class(*model_args)\n",
    "    state_dict = torch.load(f'{directory}/model_{idx}.pth')\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(idx):\n",
    "    model_class = get_model_class(name)\n",
    "    torch.manual_seed(idx)\n",
    "    model = model_class(*model_args)\n",
    "    return model\n",
    "\n",
    "def get_model_from_curve(p_curve, t):\n",
    "    model_class = get_model_class(name)\n",
    "    # Get the state_dict at t\n",
    "    state_dict_values = p_curve.weights(t=t, concatenate=False)\n",
    "    state_dict = torch.load(f'{directory}/model_{0}.pth')\n",
    "    for i, key in enumerate(state_dict.keys()):\n",
    "        state_dict[key] = state_dict_values[i]\n",
    "    # Create the model\n",
    "    m = model_class(*model_args)\n",
    "    m.load_state_dict(state_dict)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curves_gradients(p_curves, ts=np.linspace(0.0, 1.0, 101)):\n",
    "    # Takes in list of curves, and computes gradients for each curve at each point on the curve\n",
    "    # Returns a list of gradients\n",
    "    curve_grads = np.zeros((len(p_curves), len(ts), *X_test.shape))\n",
    "    for i, p_curve in enumerate(p_curves):\n",
    "        for j, t in enumerate(ts):\n",
    "            model = get_model_from_curve(curve=p_curve, t=t)\n",
    "            curve_grads[i,j] = model.compute_gradients(X_test, return_numpy=True)\n",
    "    return curve_grads\n",
    "\n",
    "def perturb_curve(p_curve, ts, n_weight_perturbations, sigma, disable_tqdm=True):\n",
    "    state_dicts = [get_model_from_curve(p_curve, t).state_dict() for t in ts]\n",
    "    return perturb_segment(state_dicts, n_weight_perturbations, sigma, disable_tqdm=disable_tqdm)\n",
    "\n",
    "def perturb_segment(state_dicts, n_weight_perturbations, sigma, disable_tqdm=True):\n",
    "    model_class = get_model_class(name)\n",
    "    logits_smooth = np.zeros((len(state_dicts), n_weight_perturbations, *y_test.shape, 2))\n",
    "    grads_smooth = np.zeros((len(state_dicts), n_weight_perturbations, *X_test.shape))\n",
    "\n",
    "    for i, state_dict in tqdm(enumerate(state_dicts), disable=disable_tqdm):\n",
    "        model = model_class(*model_args)\n",
    "        model.load_state_dict(state_dict)\n",
    "        pert_model = TabularModelPerturb(model, n_weight_perturbations, sigma)\n",
    "        logits_smooth[i] = pert_model.forward(torch.FloatTensor(X_test)).detach().numpy()\n",
    "        grads_smooth[i] = pert_model.compute_gradients(X_test, mean=False)\n",
    "    \n",
    "    return logits_smooth, grads_smooth\n",
    "\n",
    "def eval_segment(state_dicts, disable_tqdm=True):\n",
    "    model_class = get_model_class(name)\n",
    "    logits = np.zeros((len(state_dicts), *y_test.shape, 2))\n",
    "    grads = np.zeros((len(state_dicts), *X_test.shape))\n",
    "\n",
    "    for i, state_dict in tqdm(enumerate(state_dicts), disable=disable_tqdm):\n",
    "        model = model_class(*model_args)\n",
    "        model.load_state_dict(state_dict)\n",
    "        logits[i] = model.forward(torch.FloatTensor(X_test)).detach().numpy()\n",
    "        grads[i] = model.compute_gradients(X_test)\n",
    "\n",
    "    return logits, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_connect(models, trainloader, lr, epochs, curve_type='polychain', optim='sgd',\n",
    "                 ts=np.linspace(0, 1, 101), disable_tqdm=True, fix_start=False, fix_end=False):\n",
    "    if curve_type == 'polychain':\n",
    "        curve_type = curves.PolyChain\n",
    "    elif curve_type == 'bezier':\n",
    "        curve_type = curves.Bezier\n",
    "    else:\n",
    "        raise ValueError(f'Unknown curve type {curve_type}')\n",
    "    p_curve = curves.train_curve(models=models, trainloader=trainloader,\n",
    "                                 curve_class=TabularModelCurve, curve=curve_type,\n",
    "                                 input_size=model_args[0], hidden_layers=model_args[1],\n",
    "                                 fix_start=fix_start, fix_end=fix_end, optim=optim,\n",
    "                                 lr=lr, epochs=epochs, disable_tqdm=disable_tqdm)\n",
    "    # Compute gradients\n",
    "    p_curve_logits = np.zeros((len(ts), *y_test.shape, 2))\n",
    "    p_curve_grads = np.zeros((len(ts), *X_test.shape))\n",
    "    for j, t in enumerate(ts):\n",
    "        model = get_model_from_curve(p_curve=p_curve, t=t)\n",
    "        p_curve_logits[j] = model.forward(torch.FloatTensor(X_test)).detach().numpy()\n",
    "        p_curve_grads[j] = model.compute_gradients(X_test, return_numpy=True)\n",
    "    return p_curve, p_curve_logits, p_curve_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curve_statistics(p_curve, ts=np.linspace(0,1,101)):\n",
    "    # Compute losses\n",
    "    loss_fn = torch.nn.functional.cross_entropy\n",
    "    p_curve_loss = np.zeros(len(ts))\n",
    "    p_curve_loss_tr = np.zeros(len(ts))\n",
    "    p_curve_preds_tr = np.zeros((len(ts), *y_train.shape))\n",
    "    p_curve_grads_tr = np.zeros((len(ts), *X_train.shape))\n",
    "    for i, t in enumerate(ts):\n",
    "        model = get_model_from_curve(p_curve=p_curve, t=t)\n",
    "        p_curve_loss[i] = loss_fn(model.forward(torch.FloatTensor(X_test)), torch.tensor(y_test)).item()\n",
    "        p_curve_loss_tr[i] = loss_fn(model.forward(torch.FloatTensor(X_train)), torch.tensor(y_train)).item()\n",
    "        p_curve_preds_tr[i] = model.predict(X_train, return_numpy=True)\n",
    "        p_curve_grads_tr[i] = model.compute_gradients(X_train, return_numpy=True)\n",
    "    weight_norms = np.zeros(len(ts))\n",
    "    weight_diffs = np.zeros(len(ts))\n",
    "    for i, t in enumerate(ts):\n",
    "        model_t = get_model_from_curve(p_curve=p_curve, t=t)\n",
    "        model_0 = get_model_from_curve(p_curve=p_curve, t=0)\n",
    "        weight_norms[i] = get_weight_norm(model_t.state_dict())\n",
    "        weight_diffs[i] = get_weight_diff(model_t.state_dict(), model_0.state_dict())\n",
    "    return p_curve_loss, p_curve_loss_tr, p_curve_preds_tr, p_curve_grads_tr, weight_norms, weight_diffs\n",
    "\n",
    "def plot_statistics(p_curve_loss, p_curve_loss_tr,\n",
    "                    p_curve_preds, p_curve_preds_tr,\n",
    "                    p_curve_grads, p_curve_grads_tr,\n",
    "                    weight_norms, weight_diffs, ts=np.linspace(0,1,101)):\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(20, 4), dpi=150)\n",
    "    ax[0].plot(ts, p_curve_loss, label='Test')\n",
    "    ax[0].plot(ts, p_curve_loss_tr, label='Train')\n",
    "\n",
    "    ax[1].plot(ts, 100*(p_curve_preds==y_test).mean(axis=1), label='Test')\n",
    "    ax[1].plot(ts, 100*(p_curve_preds_tr==y_train).mean(axis=1), label='Train')\n",
    "\n",
    "    q = np.quantile(np.linalg.norm(p_curve_grads, axis=2), [0.25, 0.5, 0.75], axis=1)\n",
    "    ax[2].plot(ts, q[1], label='Test')\n",
    "    ax[2].fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "    q = np.quantile(np.linalg.norm(p_curve_grads_tr, axis=2), [0.25, 0.5, 0.75], axis=1)\n",
    "    ax[2].plot(ts, q[1], label='Train')\n",
    "    ax[2].fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "\n",
    "    topk, signs = get_top_k(5, p_curve_grads, return_sign=True)\n",
    "    gt_score = ground_truth_score(topk, signs, gt, signs_gt, top_k_sa)\n",
    "    q = np.quantile(gt_score, [0.25, 0.5, 0.75], axis=1)\n",
    "    ax[3].plot(ts, q[1], label='Test')\n",
    "    ax[3].fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "\n",
    "    ax[4].plot(ts, weight_norms, label='Weight Norm')\n",
    "    ax[4].plot(ts, weight_diffs, label='Weight Diff')\n",
    "\n",
    "    titles = ['Loss', 'Accuracy (%)', 'Gradient Norm', 'Ground Truth SA Similarity', 'Weight Norm']\n",
    "    for i in range(5):\n",
    "        ax[i].set_xlabel('t')\n",
    "        ax[i].legend()\n",
    "        ax[i].set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = np.array([np.load(f'{directory}/grads_{idx}.npy') for idx in range(n_models)])\n",
    "gt, signs_gt = get_top_k(5, grads.mean(axis=0), return_sign=True)\n",
    "tk, s = get_top_k(5, grads, return_sign=True)\n",
    "orig_sa = average_ground_truth_score(tk, s, gt, signs_gt, top_k_sa)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some captum bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import DeepLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(0)\n",
    "DLS = DeepLift(model)\n",
    "x = torch.FloatTensor(X_test)\n",
    "x.requires_grad = True\n",
    "dls = DLS.attribute(x, target=1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.load(f'{directory}/grads_0.npy')[:5]\n",
    "plot_grads(g*X_test[:5], nrows=1, ncols=g.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from style import plot_grads\n",
    "plot_grads(dls, nrows=1, ncols=dls.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = DeepLiftShap(model)\n",
    "n_samples = 500\n",
    "kshaps = np.zeros((n_samples, X_test.shape[1]))\n",
    "for i in tqdm(range(n_samples)):\n",
    "    kshaps[i] = ks.attribute(torch.FloatTensor(X_test[i:i+1])).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(0)\n",
    "ks = KernelShap(model)\n",
    "n_samples = 2000\n",
    "kshaps = np.zeros((100, X_test.shape[1]))\n",
    "for i in tqdm(range(100)):\n",
    "    kshaps[i] = ks.attribute(torch.FloatTensor(X_test[i:i+1]),\n",
    "    target=1, n_samples=n_samples, perturbations_per_eval=5000).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14*1000/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_ks, s_ks = get_top_k(5, kshaps, return_sign=True)\n",
    "ks_sa = average_pairwise_score(tk_ks, s_ks, top_k_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "model = load_model(0)\n",
    "explainer = shap.DeepExplainer(model, torch.FloatTensor(X_train))\n",
    "shap_values = explainer.shap_values(torch.FloatTensor(X_test[:10]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modconn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for OT-Fusion\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.ground_metric = 'euclidean'\n",
    "        self.ground_metric_normalize = 'none'\n",
    "        self.reg = 1\n",
    "        self.not_squared = False\n",
    "        self.ground_metric_eff = False\n",
    "        self.clip_min = 0\n",
    "        self.clip_max = 1000\n",
    "        self.clip_gm = False\n",
    "        self.dist_normalize = True\n",
    "        self.activation_histograms = True\n",
    "        self.act_num_samples = 100\n",
    "        self.geom_ensemble_type = 'wts'\n",
    "        self.normalize_wts = False\n",
    "        self.debug = False\n",
    "        self.exact = True\n",
    "        self.unbalanced = True\n",
    "        self.past_correction = False\n",
    "        self.ensemble_step = 0.9\n",
    "        self.bias = True\n",
    "\n",
    "args = Args()\n",
    "model_0 = load_model(0)\n",
    "model_1 = init_model(1)\n",
    "networks = [model_1, model_0]\n",
    "\n",
    "# Align model 1 to model 0\n",
    "avg_aligned_layers = align_networks(args, networks)\n",
    "model_a = load_aligned_model(avg_aligned_layers, TabularModel,\n",
    "                                   model_args, bias=args.bias)\n",
    "curve_models = [model_0, model_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
    "model_0 = load_model(0)\n",
    "model_1 = load_model(1)\n",
    "model_2 = load_model(2)\n",
    "model_1_to_0 = align_tabular(model_1, model_0, trainloader, model_args)  # align model 1 to model 0\n",
    "model_0_to_1 = align_tabular(model_0, model_1, trainloader, model_args)  # align model 0 to model 1\n",
    "model_a2 = align_tabular(model_2, model_0, trainloader, model_args)  # align model 2 to model 0\n",
    "curve_models = [model_0, model_1_to_0, model_0_to_1, model_1]#, model_a2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, 1, 50)\n",
    "p_curve, p_curve_preds, p_curve_grads = mode_connect(curve_models, trainloader=trainloader, lr=lr, optim=optim,\n",
    "                                                     epochs=60, curve_type='bezier', ts=ts,\n",
    "                                                     disable_tqdm=False, fix_start=True, fix_end=True)\n",
    "outputs = get_curve_statistics(p_curve, ts=ts)\n",
    "p_curve_loss, p_curve_loss_tr, p_curve_preds_tr, p_curve_grads_tr, weight_norms, weight_diffs = outputs\n",
    "plot_statistics(p_curve_loss, p_curve_loss_tr, p_curve_preds.argmax(axis=2), p_curve_preds_tr,\n",
    "                p_curve_grads, p_curve_grads_tr, weight_norms, weight_diffs, ts=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_idx = [10] + [11+i for i in range(num_bends)] + [11+num_bends]\n",
    "model_idx = range(2)\n",
    "g2 = np.array([np.load(f'{directory}/grads_{idx}.npy') for idx in model_idx]).mean(axis=0)\n",
    "tk_g2, s_g2 = get_top_k(5, g2, return_sign=True)\n",
    "sa_g2 = top_k_sa(tk_g2, gt, s_g2, signs_gt)\n",
    "tk_mode, s_mode = get_top_k(5, p_curve_grads.mean(axis=0), return_sign=True)\n",
    "sa_mode = top_k_sa(tk_mode, gt, s_mode, signs_gt)\n",
    "plt.boxplot([orig_sa, sa_g2, sa_mode], labels=['Original', 'G2', 'Mode'])\n",
    "plt.show()\n",
    "print(sa_mode.mean(), sa_g2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, 1, 50)\n",
    "num_bends = 2\n",
    "grads_e = []\n",
    "grads_mode = []\n",
    "for trial in tqdm(range(10)):\n",
    "    model_idx = np.random.choice(n_models, num_bends+2, replace=False)\n",
    "    models = [load_model(model_idx[0])]+[init_model(i) for i in model_idx[1:-1]]+[load_model(model_idx[-1])]\n",
    "    p_curve, p_curve_preds, p_curve_grads = mode_connect(models, trainloader=trainloader, lr=lr, optim=optim,\n",
    "                                                        epochs=100, curve_type='bezier', ts=ts,\n",
    "                                                        disable_tqdm=False, fix_start=True, fix_end=True)\n",
    "    grads_e.append(np.array([np.load(f'{directory}/grads_{idx}.npy') for idx in model_idx]).mean(axis=0))\n",
    "    grads_mode.append(p_curve_grads)\n",
    "grads_e = np.array(grads_e)\n",
    "grads_mode = np.array(grads_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_mode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "grads = np.array([np.load(f'{directory}/grads_{idx}.npy') for idx in range(n_models)])\n",
    "gt, signs_gt = get_top_k(k, grads.mean(axis=0), return_sign=True)\n",
    "\n",
    "tk, s = get_top_k(k, grads, return_sign=True)\n",
    "orig_sa = average_ground_truth_score(tk, s, gt, signs_gt, top_k_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_mode, s_mode = get_top_k(k, grads_mode.mean(axis=1), return_sign=True)\n",
    "mode_sa = average_ground_truth_score(tk_mode, s_mode, gt, signs_gt, top_k_sa)\n",
    "\n",
    "tk_e, s_e = get_top_k(k, grads_e, return_sign=True)\n",
    "e_sa = average_ground_truth_score(tk_e, s_e, gt, signs_gt, top_k_sa)\n",
    "\n",
    "plt.boxplot([orig_sa, e_sa, mode_sa])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_mode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk1, s1 = get_top_k(5, grads_e[:5].mean(axis=0), return_sign=True)\n",
    "tk2, s2 = get_top_k(5, grads_e[5:].mean(axis=0), return_sign=True)\n",
    "g1_sa = top_k_sa(tk1, gt, s1, signs_gt)\n",
    "g2_sa = top_k_sa(tk2, gt, s2, signs_gt)\n",
    "\n",
    "tkm1, sm1 = get_top_k(5, grads_mode[:5].mean(axis=(0,1)), return_sign=True)\n",
    "tkm2, sm2 = get_top_k(5, grads_mode[5:].mean(axis=(0,1)), return_sign=True)\n",
    "m1_sa = top_k_sa(tkm1, gt, sm1, signs_gt)\n",
    "m2_sa = top_k_sa(tkm2, gt, sm2, signs_gt)\n",
    "\n",
    "g15_sa = average_ground_truth_score(np.array([tk1, tk2]), np.array([s1, s2]), gt, signs_gt, top_k_sa)\n",
    "m15_sa = average_ground_truth_score(np.array([tkm1, tkm2]), np.array([sm1, sm2]), gt, signs_gt, top_k_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([g15_sa, m15_sa], labels=['G15', 'Mode'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sa = average_ground_truth_score(tk, s, gt, signs_gt, top_k_sa)\n",
    "tk_mode, s_mode = get_top_k(5, grads_mode.mean(axis=1), return_sign=True)\n",
    "mode_sa = average_ground_truth_score(tk_mode, s_mode, gt, signs_gt, top_k_sa)\n",
    "gm30 = grads_mode.mean(axis=(0,1))\n",
    "tk_gm30, s_gm30 = get_top_k(5, gm30, return_sign=True)\n",
    "gm30_sa = top_k_sa(tk_gm30, gt, s_gm30, signs_gt)\n",
    "g30 = grads_e.mean(axis=0)\n",
    "tk_g30, s_g30 = get_top_k(5, g30, return_sign=True)\n",
    "g30_sa = top_k_sa(tk_g30, gt, s_g30, signs_gt)\n",
    "plt.boxplot([orig_sa, mode_sa, gm30_sa, g30_sa], labels=['Original', 'Mode', 'Full Mode', 'Avg'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = np.zeros((len(ts), 10))\n",
    "for i, t in enumerate(ts):\n",
    "    coeff[i] = p_curve.coeff_layer(t)\n",
    "for i in range(coeff.shape[1]):\n",
    "    plt.plot(ts, coeff[:,i], label=f'{i}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_preds = np.zeros((2, len(X_test)))\n",
    "orig_grads = np.zeros((2, len(X_test), 23))\n",
    "for i in range(2):\n",
    "    model = load_model(i)\n",
    "    orig_preds[i] = model.predict(X_test, return_numpy=True)\n",
    "    orig_grads[i] = model.compute_gradients(X_test, return_numpy=True)\n",
    "orig_tk, orig_s = get_top_k(5, orig_grads, return_sign=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "predsim = np.zeros((2, len(epoch), len(ts)))\n",
    "gradsim = np.zeros((2, len(epoch), len(ts)))\n",
    "sa = np.zeros((2, len(epoch), len(ts), n_inputs))\n",
    "for i, ep in enumerate(epoch):\n",
    "    models = [init_model(i) for i in range(2)]\n",
    "    p_curve, p_curve_preds, p_curve_grads = mode_connect(models, trainloader=trainloader, lr=lr, optim=optim,\n",
    "                                                     epochs=ep, curve_type='bezier', ts=ts,\n",
    "                                                     disable_tqdm=False, fix_start=False, fix_end=False)\n",
    "    for m in range(2):\n",
    "        predsim[m,i] = (p_curve_preds.argmax(axis=2)==orig_preds[m]).mean(axis=1)\n",
    "        gradsim[m,i] = np.linalg.norm(p_curve_grads-orig_grads[m], axis=2).mean(axis=1)\n",
    "        ep_tk, ep_s = get_top_k(5, p_curve_grads, return_sign=True)\n",
    "        for j, t in enumerate(ts):\n",
    "            sa[m,i,j] = top_k_sa(orig_tk[m], ep_tk[j], orig_s[m], ep_s[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch, gradsim[0,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch, np.mean(sa[0, :, 0], axis=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15,5), dpi=150)\n",
    "idx = 1\n",
    "for i, ep in enumerate(epoch):\n",
    "    if ep in [5, 10, 20, 30, 35, 40, 45, 50]:\n",
    "        ax[0].plot(ts, predsim[idx, i], label=f'{ep}')\n",
    "        ax[1].plot(ts, gradsim[idx, i], label=f'{ep}')\n",
    "        ax[2].plot(ts, sa[idx, i].mean(axis=1), label=f'{ep}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds0\n",
    "preds20 = np.zeros((2, len(X_test)))\n",
    "grads20 = np.zeros((2, len(X_test), 23))\n",
    "\n",
    "for i in range(2):\n",
    "    model = load_model(i)\n",
    "    preds20[i] = \n",
    "    grads20[i] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, 1, 51)\n",
    "model_class = get_model_class(name)\n",
    "models = [init_model(i) for i in range(2)]\n",
    "torch.manual_seed(9)\n",
    "p_curve, p_curve_preds, p_curve_grads = mode_connect(models, trainloader=trainloader, lr=lr, optim=optim,\n",
    "                                                     epochs=epochs+10, curve_type='bezier', ts=ts,\n",
    "                                                     disable_tqdm=False, init='none', target_loss=0)\n",
    "outputs = get_curve_statistics(p_curve, ts=ts)\n",
    "p_curve_loss, p_curve_loss_tr, p_curve_preds_tr, p_curve_grads_tr, weight_norms, weight_diffs = outputs\n",
    "plot_statistics(p_curve_loss, p_curve_loss_tr, p_curve_preds.argmax(axis=2), p_curve_preds_tr,\n",
    "                p_curve_grads, p_curve_grads_tr, weight_norms, weight_diffs, ts=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_model = get_model_from_curve(p_curve, t=0.5)\n",
    "p_curve2, p_curve_preds2, p_curve_grads2 = mode_connect([start_model, mid_model], trainloader=trainloader_full,\n",
    "                                                     num_bends=3, lr=0.04, momentum=0,\n",
    "                                                     epochs=15, curve_type='polychain',\n",
    "                                                     ts=ts, disable_tqdm=False,\n",
    "                                                     init='radial', target_loss=0.55)\n",
    "outputs2 = get_curve_statistics(p_curve2, ts=ts)\n",
    "p_curve_loss2, p_curve_loss_tr2, p_curve_preds_tr2, p_curve_grads_tr2, weight_norms2, weight_diffs2 = outputs2\n",
    "plot_statistics(p_curve_loss2, p_curve_loss_tr2, p_curve_preds2, p_curve_preds_tr2,\n",
    "                p_curve_grads2, p_curve_grads_tr2, weight_norms2, weight_diffs2, ts=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from style import plot_grads\n",
    "n_plot = 7\n",
    "skip = len(ts) // (n_plot-1)\n",
    "plot_ts = np.arange(0, len(ts), skip)\n",
    "plot_grads(p_curve_grads[plot_ts, 0], nrows=1, ncols=n_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_grads1(p_curve, ts=np.linspace(0,1,101)):\n",
    "    p_curve_grads = np.zeros((len(ts), *X_test.shape))\n",
    "    for i, t in enumerate(ts):\n",
    "        model = get_model_from_curve(p_curve=p_curve, t=t)\n",
    "        p_curve_grads[i] = model.compute_gradients(X_test, return_numpy=True)\n",
    "    return p_curve_grads\n",
    "\n",
    "import torch.nn as nn\n",
    "def curve_grads2(p_curve, ts=np.linspace(0,1,101)):\n",
    "    models = nn.ModuleList(modules=[get_model_from_curve(p_curve=p_curve, t=t) for t in ts])\n",
    "    p_curve_grads = [model.compute_gradients(X_test, return_numpy=True) for model in models]\n",
    "    return np.array(p_curve_grads)\n",
    "    \n",
    "model_class = get_model_class(name)\n",
    "def curve_grads3(p_curve, ts=np.linspace(0,1,101)):\n",
    "    p_curve_grads = p_curve.compute_gradients(X_test, model_class, ts)\n",
    "    return p_curve_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_curve_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit curve_grads1(p_curve, ts=np.linspace(0,1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit curve_grads2(p_curve, ts=np.linspace(0,1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit curve_grads3(p_curve, ts=np.linspace(0,1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_curve_grads1 = curve_grads1(p_curve, ts=np.linspace(0,1,101))\n",
    "p_curve_grads2 = curve_grads2(p_curve, ts=np.linspace(0,1,101))\n",
    "p_curve_grads3 = curve_grads3(p_curve, ts=np.linspace(0,1,101))\n",
    "\n",
    "assert np.allclose(p_curve_grads1, p_curve_grads2)\n",
    "assert np.allclose(p_curve_grads1, p_curve_grads3)\n",
    "assert np.allclose(p_curve_grads2, p_curve_grads3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_diffs = np.zeros(len(ts))\n",
    "grad_diffs = np.zeros((len(ts), X_test.shape[0]))\n",
    "SA = np.zeros((len(ts), X_test.shape[0]))\n",
    "for i, t in enumerate(ts):\n",
    "    model_0 = get_model_from_curve(p_curve=p_curve, t=0)\n",
    "    model_t = get_model_from_curve(p_curve=p_curve, t=t)\n",
    "    weight_diffs[i] = get_weight_diff(model_0.state_dict(), model_t.state_dict())\n",
    "    grad_0, grad_t = model_0.compute_gradients(X_test, return_numpy=True), model_t.compute_gradients(X_test, return_numpy=True)\n",
    "    grad_diffs[i] = np.linalg.norm(grad_0-grad_t, axis=1)\n",
    "    tk_0, s_0 = get_top_k(5, grad_0, return_sign=True)\n",
    "    tk_t, s_t = get_top_k(5, grad_t, return_sign=True)\n",
    "    SA[i] = top_k_sa(tk_0, tk_t, s_0, s_t)\n",
    "#plt.plot(ts, weight_diffs)\n",
    "q = np.quantile(grad_diffs, q=[0.25, 0.5, 0.75], axis=1)\n",
    "plt.plot(ts, q[1])\n",
    "plt.fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.quantile(SA, q=[0.25, 0.5, 0.75], axis=1)\n",
    "plt.plot(ts, q[1])\n",
    "plt.fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to Glory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test point indices\n",
    "test_idx = range(X_test.shape[0])\n",
    "x = X_test[test_idx]\n",
    "\n",
    "# Random source\n",
    "random_source = random_sources[0]\n",
    "\n",
    "# Number of ensembles to sample\n",
    "n_trials = 10\n",
    "\n",
    "# Top-k features to consider\n",
    "k = 5\n",
    "\n",
    "# Store no. inputs and no. features\n",
    "n_inputs, n_features = X_test.shape\n",
    "\n",
    "# Curve/Segment/Smooth Params\n",
    "ts = np.linspace(0,1,21)\n",
    "n_weight_perturbations = 100\n",
    "sigma = 0.5\n",
    "\n",
    "# Ensemble\n",
    "ensemble_size = 2  # rough optimal epochs for 2, 3, 4, 5: 30, 40, 60, 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute random pairs\n",
    "# Compute random mode-connected pairs\n",
    "# Compute random perturbed pairs\n",
    "\n",
    "topk_avg, signs_avg = np.zeros((n_trials, n_inputs, k)), np.zeros((n_trials, n_inputs, k))\n",
    "topk_smooth, signs_smooth = np.zeros((n_trials, n_inputs, k)), np.zeros((n_trials, n_inputs, k))\n",
    "topk_mode, signs_mode = np.zeros((n_trials, n_inputs, k)), np.zeros((n_trials, n_inputs, k))\n",
    "topk_mode_smooth, signs_mode_smooth = np.zeros((n_trials, n_inputs, k)), np.zeros((n_trials, n_inputs, k))\n",
    "# topk_seg, signs_seg = np.zeros((n_trials, n_inputs, k)), np.zeros((n_trials, n_inputs, k))\n",
    "# topk_seg_smooth, signs_seg_smooth = np.zeros((n_trials, n_inputs, k)), np.zeros((n_trials, n_inputs, k))\n",
    "\n",
    "accs_avg = np.zeros(n_trials)\n",
    "accs_smooth = np.zeros(n_trials)\n",
    "accs_mode = np.zeros(n_trials)\n",
    "accs_mode_smooth = np.zeros(n_trials)\n",
    "# accs_seg = np.zeros(n_trials)\n",
    "# accs_seg_smooth = np.zeros(n_trials)\n",
    "model_class = get_model_class(name)\n",
    "\n",
    "for i in tqdm(range(n_trials)):\n",
    "    # Sample random models\n",
    "    model_idx = range(800+i*ensemble_size, 800+(i+1)*ensemble_size)\n",
    "    \n",
    "    # Load predictions/gradients\n",
    "    grads = np.array([np.load(f'{directory}/{random_source}_grads_{idx}.npy') for idx in model_idx])\n",
    "    logits = np.array([np.load(f'{directory}/{random_source}_logits_{idx}.npy') for idx in model_idx]).mean(axis=0)\n",
    "    preds = logits.argmax(axis=1)\n",
    "\n",
    "    grads_smooth = np.array([np.load(f'{directory}/{random_source}_grads_smooth_{idx}.npy') for idx in model_idx])\n",
    "    logits_smooth = np.array([np.load(f'{directory}/{random_source}_logits_smooth_{idx}.npy') for idx in model_idx]).mean(axis=0)\n",
    "    preds_smooth = logits_smooth.argmax(axis=1)\n",
    "\n",
    "    # Mode connectivity\n",
    "    #start_model, end_model = load_model(model_idx[0]), load_model(model_idx[1])\n",
    "    models = [init_model(idx) for idx in model_idx]\n",
    "    p_curve, logits_mode, grads_mode = mode_connect(models, trainloader=trainloader_full, lr=0.0004,\n",
    "                                                     momentum=0, epochs=30, curve_type='bezier', ts=ts,\n",
    "                                                     disable_tqdm=False, init='none', target_loss=0)\n",
    "        # models, trainloader=trainloader_full,\n",
    "        #                                             lr=0.1, momentum=0,\n",
    "        #                                              epochs=80, curve_type='bezier',\n",
    "        #                                              ts=ts, disable_tqdm=True,\n",
    "        #                                              init='none', target_loss=0)\n",
    "                                                    #  num_bends=3, lr=0.1, momentum=0,\n",
    "                                                    #  epochs=20, curve_type='polychain',\n",
    "                                                    #  ts=ts, disable_tqdm=True,\n",
    "                                                    #  init='radial', target_loss=0)\n",
    "    preds_mode = logits_mode.mean(axis=0).argmax(axis=1)\n",
    "\n",
    "    # Perturb Curve\n",
    "    logits_mode_smooth, grads_mode_smooth = perturb_curve(p_curve, ts=ts,\n",
    "                                                     n_weight_perturbations=n_weight_perturbations,\n",
    "                                                     sigma=sigma, disable_tqdm=True)\n",
    "    preds_mode_smooth = logits_mode_smooth.mean(axis=(0,1)).argmax(axis=1)\n",
    "    \n",
    "    # # Segment\n",
    "    # state_dict1, state_dict2 = load_model(model_idx[0]).state_dict(), load_model(model_idx[1]).state_dict()\n",
    "    # state_dicts = linear_weight_interpolation(state_dict1, state_dict2, ts=ts)\n",
    "    # logits_seg, grads_seg = eval_segment(state_dicts, disable_tqdm=True)\n",
    "    # logits_seg_smooth, grads_seg_smooth = perturb_segment(state_dicts, n_weight_perturbations,\n",
    "    #                                                       sigma, disable_tqdm=True)\n",
    "    \n",
    "    # Compute top-k features\n",
    "    topk_avg[i], signs_avg[i] = get_top_k(k=k, X=grads.mean(axis=0), return_sign=True)\n",
    "    topk_smooth[i], signs_smooth[i] = get_top_k(k=k, X=grads_smooth.mean(axis=0), return_sign=True)\n",
    "    topk_mode[i], signs_mode[i] = get_top_k(k=k, X=grads_mode.mean(axis=0), return_sign=True)\n",
    "    topk_mode_smooth[i], signs_mode_smooth[i] = get_top_k(k=k, X=grads_mode_smooth.mean(axis=(0,1)), return_sign=True)\n",
    "    # topk_seg[i], signs_seg[i] = get_top_k(k=k, X=grads_seg.mean(axis=0), return_sign=True)\n",
    "    # topk_seg_smooth[i], signs_seg_smooth[i] = get_top_k(k=k, X=grads_seg_smooth.mean(axis=(0,1)), return_sign=True)\n",
    "\n",
    "    # Accuracies\n",
    "    accs_avg[i] = (preds == y_test).mean()\n",
    "    accs_smooth[i] = (preds_smooth == y_test).mean()\n",
    "    accs_mode[i] = (preds_mode == y_test).mean()\n",
    "    accs_mode_smooth[i] = (preds_mode_smooth == y_test).mean()\n",
    "    # accs_seg[i] = (logits_seg.mean(axis=0).argmax(1) == y_test).mean()\n",
    "    # accs_seg_smooth[i] = (logits_seg_smooth.mean(axis=(0,1)).argmax(1) == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_avg = average_pairwise_score(topk_avg, signs_avg, top_k_sa)\n",
    "SA_smooth = average_pairwise_score(topk_smooth, signs_smooth, top_k_sa)\n",
    "SA_mode = average_pairwise_score(topk_mode, signs_mode, top_k_sa)\n",
    "SA_mode_smooth = average_pairwise_score(topk_mode_smooth, signs_mode_smooth, top_k_sa)\n",
    "# SA_seg = average_pairwise_score(topk_seg, signs_seg, top_k_sa)\n",
    "# SA_seg_smooth = average_pairwise_score(topk_seg_smooth, signs_seg_smooth, top_k_sa)\n",
    "\n",
    "# grads_gt = np.array([np.load(f'{directory}/{random_source}_grads_{idx}.npy') for idx in range(n_models)]).mean(axis=0)\n",
    "# topk_gt, signs_gt = get_top_k(k=k, X=grads_gt, return_sign=True)\n",
    "# SA_avg_gt = average_ground_truth_score(topk_avg, signs_avg, topk_gt, signs_gt, top_k_sa)\n",
    "# SA_smooth_gt = average_ground_truth_score(topk_smooth, signs_smooth, topk_gt, signs_gt, top_k_sa)\n",
    "# SA_mode_gt = average_ground_truth_score(topk_mode, signs_mode, topk_gt, signs_gt, top_k_sa)\n",
    "# SA_mode_norm_gt = average_ground_truth_score(topk_mode_norm, signs_mode_norm, topk_gt, signs_gt, top_k_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = np.array([np.load(f'{directory}/{random_source}_grads_{idx}.npy') for idx in range(800, 820, 2)])\n",
    "preds = np.array([np.load(f'{directory}/{random_source}_preds_{idx}.npy') for idx in range(800, 820, 2)])\n",
    "accs_single = (preds == y_test).mean(axis=1)\n",
    "topk, signs = get_top_k(k=k, X=grads, return_sign=True)\n",
    "SA_single = average_pairwise_score(topk, signs, top_k_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(SA_single), np.median(SA_avg), np.median(SA_smooth), np.median(SA_mode), np.median(SA_mode_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_mode_smooth.mean(axis=(0,1)).argmax(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 3), dpi=150)\n",
    "labels = ['Single Model', 'Average', 'Perturb\\n+ Average', 'Mode Connect', 'Mode Connect\\n+ Perturb']\n",
    "ax[0].boxplot([SA_single, SA_avg, SA_smooth, SA_mode, SA_mode_smooth],#, SA_seg, SA_seg_smooth],\n",
    "              labels=labels)#, 'Segment', 'Segment + Perturb'])\n",
    "ax[0].set_ylabel('Sign Agreement (SA)')\n",
    "ax[0].set_title('Average Pairwise SA')\n",
    "# ax[1].boxplot([SA_avg_gt, SA_smooth_gt, SA_mode_gt, SA_mode_norm_gt], labels=['Average', 'Perturb + Average', 'Polychain', 'Polychain Norm'])\n",
    "# ax[1].set_ylabel('SA (Ground Truth)')\n",
    "# ax[1].set_title('Average Ground Truth SA')\n",
    "ax[1].boxplot([100*accs_single, 100*accs_avg, 100*accs_smooth, 100*accs_mode, 100*accs_mode_smooth],#, 100*accs_seg, 100*accs_seg_smooth],\n",
    "              labels=labels)#, 'Segment', 'Segment + Perturb'])\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title('Test Accuracy')\n",
    "plt.suptitle(f'HELOC Dataset: Average Pairwise SA and Test Accuracy for Size {ensemble_size} Ensembles',\n",
    "             fontweight='bold', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(24, 6), dpi=150)\n",
    "labels = ['Single Model', 'Average', 'Perturb + Average', 'Mode Connect', 'Mode Connect + Perturb']\n",
    "ax[0].boxplot([SA_single, SA_avg, SA_smooth, SA_mode, SA_mode_smooth],#, SA_seg, SA_seg_smooth],\n",
    "              labels=labels)#, 'Segment', 'Segment + Perturb'])\n",
    "ax[0].set_ylabel('SA')\n",
    "ax[0].set_title('Average Pairwise SA')\n",
    "# ax[1].boxplot([SA_avg_gt, SA_smooth_gt, SA_mode_gt, SA_mode_norm_gt], labels=['Average', 'Perturb + Average', 'Polychain', 'Polychain Norm'])\n",
    "# ax[1].set_ylabel('SA (Ground Truth)')\n",
    "# ax[1].set_title('Average Ground Truth SA')\n",
    "ax[1].boxplot([100*accs_single, 100*accs_avg, 100*accs_smooth, 100*accs_mode, 100*accs_mode_smooth],#, 100*accs_seg, 100*accs_seg_smooth],\n",
    "              labels=labels)#, 'Segment', 'Segment + Perturb'])\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title('Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(24, 6), dpi=150)\n",
    "labels = ['Single Model', 'Average', 'Perturb + Average', 'Mode Connect', 'Mode Connect + Perturb']\n",
    "ax[0].boxplot([SA_single, SA_avg, SA_smooth, SA_mode, SA_mode_smooth],#, SA_seg, SA_seg_smooth],\n",
    "              labels=labels)#, 'Segment', 'Segment + Perturb'])\n",
    "ax[0].set_ylabel('SA')\n",
    "ax[0].set_title('Average Pairwise SA')\n",
    "# ax[1].boxplot([SA_avg_gt, SA_smooth_gt, SA_mode_gt, SA_mode_norm_gt], labels=['Average', 'Perturb + Average', 'Polychain', 'Polychain Norm'])\n",
    "# ax[1].set_ylabel('SA (Ground Truth)')\n",
    "# ax[1].set_title('Average Ground Truth SA')\n",
    "ax[1].boxplot([100*accs_single, 100*accs_avg, 100*accs_smooth, 100*accs_mode, 100*accs_mode_smooth],#, 100*accs_seg, 100*accs_seg_smooth],\n",
    "              labels=labels)#, 'Segment', 'Segment + Perturb'])\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title('Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(24, 5), dpi=150)\n",
    "ax[0].boxplot([SA_avg, SA_smooth, SA_mode, SA_mode_smooth, SA_seg, SA_seg_smooth],\n",
    "              labels=['Average', 'Perturb + Average', 'Polychain', 'Polychain + Perturb', 'Segment', 'Segment + Perturb'])\n",
    "ax[0].set_ylabel('SA')\n",
    "ax[0].set_title('Average Pairwise SA')\n",
    "# ax[1].boxplot([SA_avg_gt, SA_smooth_gt, SA_mode_gt, SA_mode_norm_gt], labels=['Average', 'Perturb + Average', 'Polychain', 'Polychain Norm'])\n",
    "# ax[1].set_ylabel('SA (Ground Truth)')\n",
    "# ax[1].set_title('Average Ground Truth SA')\n",
    "ax[1].boxplot([100*accs_avg, 100*accs_smooth, 100*accs_mode, 100*accs_mode_smooth, 100*accs_seg, 100*accs_seg_smooth],\n",
    "              labels=['Average', 'Perturb + Average', 'Polychain', 'Polychain + Perturb', 'Segment', 'Segment + Perturb'])\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title('Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 5), dpi=150)\n",
    "ax[0].boxplot([SA_avg, SA_smooth, SA_mode, SA_mode_norm], labels=['Average', 'Perturb + Average', 'Polychain', 'Polychain Norm'])\n",
    "ax[0].set_ylabel('SA')\n",
    "ax[0].set_title('Average Pairwise SA')\n",
    "ax[1].boxplot([SA_avg_gt, SA_smooth_gt, SA_mode_gt, SA_mode_norm_gt], labels=['Average', 'Perturb + Average', 'Polychain', 'Polychain Norm'])\n",
    "ax[1].set_ylabel('SA (Ground Truth)')\n",
    "ax[1].set_title('Average Ground Truth SA')\n",
    "ax[2].boxplot([100*accs_avg, 100*accs_smooth, 100*accs_mode], labels=['Average', 'Perturb + Average', 'Polychain'])\n",
    "ax[2].set_ylabel('Accuracy (%)')\n",
    "ax[2].set_title('Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment + Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_weight_interpolation(state_dict1, state_dict2, ts):\n",
    "    # Interpolate between two state dicts\n",
    "    state_dicts = []\n",
    "    for t in ts:\n",
    "        state_dict = {}\n",
    "        for key in state_dict1.keys():\n",
    "            state_dict[key] = state_dict1[key] + (state_dict2[key] - state_dict1[key]) * t\n",
    "        state_dicts.append(state_dict)\n",
    "    return state_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate between two state dicts\n",
    "ts = np.linspace(0.0, 1.0, 101)\n",
    "state_dict1 = torch.load(f'{directory}/{random_source}_model_{0}.pth')\n",
    "state_dict2 = torch.load(f'{directory}/{random_source}_model_{1}.pth')\n",
    "state_dicts = linear_weight_interpolation(state_dict1, state_dict2, ts)\n",
    "\n",
    "\n",
    "# For each state dict, compute the accuracy on the test set\n",
    "segment_accs = []\n",
    "segment_accs_tr = []\n",
    "model = model_class(*model_args)\n",
    "for state_dict in tqdm(state_dicts):\n",
    "    model.load_state_dict(state_dict)\n",
    "    segment_accs.append((model.predict(X_test).numpy() == y_test).mean())\n",
    "    segment_accs_tr.append((model.predict(X_train).numpy() == y_train).mean())\n",
    "\n",
    "# Plot both plots below on one row, two columns\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5), dpi=100)\n",
    "accs = [segment_accs, segment_accs_tr]\n",
    "labs = ['Test Set', 'Train Set']\n",
    "for i in range(2):\n",
    "    ax[i].plot(ts, 100*np.array(accs[i]), label='Segment')\n",
    "    ax[i].set_xlabel('t')\n",
    "    ax[i].set_ylabel('Accuracy (%)')\n",
    "    ax[i].set_title(labs[i])\n",
    "    ax[i].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_weight_perturbations = 100\n",
    "sigma = 0.2\n",
    "\n",
    "model_class = get_model_class(name)\n",
    "model = load_model(0)\n",
    "model_pert = TabularModelPerturb(model, n_weight_perturbations, sigma)\n",
    "pert_grad = model_pert.compute_gradients(X_test, mean=False)\n",
    "pert_pred, pert_pred_tr = model_pert.predict(X_test), model_pert.predict(X_train)\n",
    "grad = model.compute_gradients(X_test)\n",
    "pred = model.predict(X_test)\n",
    "pred_tr = model.predict(X_train)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, dpi=100)\n",
    "ax[0].boxplot([np.linalg.norm(grad, axis=1), np.linalg.norm(pert_grad, axis=2).mean(axis=0)])\n",
    "ax[1].boxplot([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict1 = torch.load(f'{directory}/{random_source}_model_{0}.pth')\n",
    "state_dict2 = torch.load(f'{directory}/{random_source}_model_{1}.pth')\n",
    "ts=np.linspace(0, 1, 21)\n",
    "state_dicts = linear_weight_interpolation(state_dict1, state_dict2, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = get_model_class(name)\n",
    "accs_smooth_tr, grads_smooth = perturb_curve(p_curve, ts=np.linspace(0,1,21),\n",
    "                                             n_weight_perturbations=100, sigma=0.1, disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grads = np.array([grads_smooth[i, np.argmax(accs_smooth_tr[i])] for i in range(len(ts))])\n",
    "q = np.quantile(np.linalg.norm(best_grads, axis=2), [0.25, 0.5, 0.75], axis=1)\n",
    "plt.plot(ts, q[1])\n",
    "plt.fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "# Plot average gradient norms\n",
    "q = np.quantile(np.linalg.norm(grads_smooth.mean(axis=1), axis=2), [0.25, 0.5, 0.75], axis=1)\n",
    "plt.plot(ts, q[1])\n",
    "plt.fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "# Plot best accuracy for each t\n",
    "q = np.quantile(accs_smooth_tr, [0.25, 0.5, 0.75], axis=1)\n",
    "plt.plot(ts, q[1])\n",
    "plt.fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_perturb(state_dicts, n_weight_perturbations=100, sigma=0.5, disable_tqdm=True):\n",
    "    # For each state dict, perturb the first layer weights\n",
    "    preds_smooth = np.zeros((len(state_dicts), n_weight_perturbations, *y_test.shape))\n",
    "    preds_smooth_tr = np.zeros((len(state_dicts), n_weight_perturbations, *y_train.shape))\n",
    "    accs_smooth = np.zeros((len(state_dicts), n_weight_perturbations))\n",
    "    accs_smooth_tr = np.zeros((len(state_dicts), n_weight_perturbations))\n",
    "    grads_smooth = np.zeros((len(state_dicts), n_weight_perturbations, *X_test.shape))\n",
    "    grads_smooth_tr = np.zeros((len(state_dicts), n_weight_perturbations, *X_train.shape))\n",
    "\n",
    "    for i, state_dict in tqdm(enumerate(state_dicts), disable=disable_tqdm):\n",
    "        model = model_class(*model_args)\n",
    "        model.load_state_dict(state_dict)\n",
    "        pert_model = TabularModelPerturb(model, n_weight_perturbations, sigma)\n",
    "        preds_smooth[i] = pert_model.predict(X_test, mean=False)\n",
    "        preds_smooth_tr[i] = pert_model.predict(X_train, mean=False)\n",
    "        accs_smooth[i] = (preds_smooth[i] == y_test).mean(axis=1)\n",
    "        accs_smooth_tr[i] = (preds_smooth_tr[i] == y_train).mean(axis=1)\n",
    "        grads_smooth[i] = pert_model.compute_gradients(X_test, mean=False)\n",
    "        grads_smooth_tr[i] = pert_model.compute_gradients(X_train, mean=False)\n",
    "    return accs_smooth, accs_smooth_tr, grads_smooth, grads_smooth_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_smooth, accs_smooth_tr, grads_smooth, grads_smooth_tr =\\\n",
    "    segment_perturb(state_dicts, n_weight_perturbations=100, sigma=0.1, disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_accs = [[(load_model(0).predict(X_test, return_numpy=True)==y_test).mean(), (load_model(0).predict(X_train, return_numpy=True)==y_train).mean()],\n",
    "             [(load_model(1).predict(X_test, return_numpy=True)==y_test).mean(), (load_model(1).predict(X_train, return_numpy=True)==y_train).mean()]]\n",
    "test_acc = (TabularModelPerturb(load_model(1), 100, 0.1).predict(X_test, mean=False)==y_test).mean(axis=1)\n",
    "train_acc = (TabularModelPerturb(load_model(1), 100, 0.1).predict(X_train, mean=False)==y_train).mean(axis=1)\n",
    "plt.boxplot([test_acc, train_acc], labels=['Test', 'Train'])\n",
    "plt.show()\n",
    "print(orig_accs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test and train on two columns\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5), dpi=100)\n",
    "accs = [accs_smooth, accs_smooth_tr]\n",
    "labs = ['Test Set', 'Train Set']\n",
    "orig_accs = [[(load_model(0).predict(X_test, return_numpy=True)==y_test).mean(), (load_model(0).predict(X_train, return_numpy=True)==y_train).mean()],\n",
    "             [(load_model(1).predict(X_test, return_numpy=True)==y_test).mean(), (load_model(1).predict(X_train, return_numpy=True)==y_train).mean()]]\n",
    "for i in range(2):\n",
    "    q = np.quantile(accs[i], [0, 0.5, 1.0], axis=1)\n",
    "    ax[i].plot(ts, q[1])\n",
    "    ax[i].scatter([0,1], orig_accs[i], color='blue')\n",
    "    ax[i].fill_between(ts, q[0], q[2], alpha=0.5)\n",
    "    ax[i].set_xlabel('t')\n",
    "    ax[i].set_ylabel('Accuracy (%)')\n",
    "    ax[i].set_title(labs[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accs = accs_smooth_tr.argmax(1)\n",
    "# For each element in grads_smooth, select the best_accs[i]th row\n",
    "best_grads = np.array([grads_smooth[i, best_accs[i]] for i in range(len(best_accs))])\n",
    "best_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.quantile(np.linalg.norm(best_grads, axis=2), [0.25, 0.5, 0.75], axis=1)\n",
    "plt.plot(ts, q[1])\n",
    "plt.fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
