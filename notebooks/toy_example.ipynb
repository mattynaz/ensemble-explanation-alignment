{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps as cmaps\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "import datasets\n",
    "import torch\n",
    "from datasets.tabular import TabularModel, TabularModelPerturb, learning_pipeline\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from similarity import get_top_k, top_k_sa, average_pairwise_score, ground_truth_score, average_ground_truth_score\n",
    "from similarity import angle_diff, average_pairwise_score_grad, cosine_similarity\n",
    "from util import State, get_weight_norm, get_weight_diff, linear_weight_interpolation\n",
    "from train import get_states\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoMoons(Dataset):\n",
    "    def __init__(self, n_samples=1000, noise=0.1, random_state=0, circles=False):\n",
    "        if circles:\n",
    "            X, y = make_circles(n_samples=n_samples, noise=noise,\n",
    "                                factor=0.5, random_state=random_state)\n",
    "        else:\n",
    "            X, y = make_moons(n_samples=n_samples, noise=noise,\n",
    "                              random_state=random_state)\n",
    "        self.name = 'moons'\n",
    "        self.data = torch.FloatTensor(X)\n",
    "        self.labels = torch.LongTensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the length of the dataset. Necessary for PyTorch's DataLoader.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return the sample at index idx. Necessary for PyTorch's DataLoader.\"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = False\n",
    "trainset = TwoMoons(n_samples=800, noise=0.4, random_state=0, circles=circles)\n",
    "testset = TwoMoons(n_samples=200, noise=0.4, random_state=1, circles=circles)\n",
    "# trainset.data[trainset.labels==1, 0] -= 0.5\n",
    "# testset.data[testset.labels==1, 0] -= 0.5\n",
    "X_test, y_test = testset.data.numpy(), testset.labels.numpy()\n",
    "n_inputs, n_features = X_test.shape\n",
    "X_train, y_train = trainset.data.numpy(), trainset.labels.numpy()\n",
    "\n",
    "# Plot trainset and test set on two columns\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.scatter(trainset.data[:, 0], trainset.data[:, 1], c=trainset.labels, s=2)\n",
    "ax2.scatter(testset.data[:, 0], testset.data[:, 1], c=testset.labels, s=2)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 200\n",
    "config = {'n': n_models,\n",
    "          'optimizer': 'adam',\n",
    "          'epochs': 100,\n",
    "          'lr': 0.004,\n",
    "          'batch_size': 16,\n",
    "          'loo': False,\n",
    "          'seed': 0,\n",
    "          'mode_connect': '',\n",
    "          'wandb': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "config['epochs'] = 100\n",
    "config['mode_connect'] = ''\n",
    "States = get_states(n_models, TabularModel, trainset, testset, config)\n",
    "for S in States:\n",
    "    models.append(learning_pipeline(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_models = []\n",
    "config['epochs'] = 100\n",
    "config['mode_connect'] = 'bezier'\n",
    "States = get_states(n_models, TabularModel, trainset, testset, config)\n",
    "for S in States:\n",
    "    mode_models.append(learning_pipeline(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute perturbed models\n",
    "num_perturbations = 50\n",
    "sigma = 0.2\n",
    "pert_models = []\n",
    "for model in tqdm(models):\n",
    "    pert_model = TabularModelPerturb(model, num_perturbations, sigma)\n",
    "    pert_models.append(pert_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(method, X, idx):\n",
    "    if method == 'average':\n",
    "        logits = models[idx](torch.FloatTensor(X)).detach().numpy()\n",
    "        grads = models[idx].compute_gradients(torch.FloatTensor(X), return_numpy=True)\n",
    "    elif method == 'perturb':\n",
    "        logits = pert_models[idx](torch.FloatTensor(X)).detach().numpy().mean(axis=0)\n",
    "        grads = pert_models[idx].compute_gradients(X, mean=True)\n",
    "    elif method == 'mode connect':\n",
    "        logits = mode_models[idx].compute_logits(X, TabularModel, ts).mean(axis=0)\n",
    "        grads = mode_models[idx].compute_gradients(X, TabularModel, ts).mean(axis=0)\n",
    "    return logits, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0,1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['average', 'perturb', 'mode connect']\n",
    "logits = np.zeros((len(methods), n_models, n_inputs, 2))\n",
    "grads = np.zeros((len(methods), n_models, n_inputs, n_features))\n",
    "angles = np.zeros((len(methods), n_inputs))\n",
    "accs = np.zeros((len(methods), n_models))\n",
    "for i, method in enumerate(tqdm(methods)):\n",
    "    for j, model in enumerate(models):\n",
    "        logits[i, j], grads[i, j] = get_stats(method, X_test, j)\n",
    "    angles[i] = average_pairwise_score_grad(grads[i], angle_diff)\n",
    "    accs[i] = (logits[i].argmax(axis=2) == y_test).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5), dpi=100)\n",
    "for i, method in enumerate(methods):\n",
    "    ax[0].boxplot([angles[i] for i in range(len(methods))], labels=methods)\n",
    "    ax[0].set_title('Angle between gradients')\n",
    "    ax[1].boxplot([accs[i] for i in range(len(methods))], labels=methods)\n",
    "    ax[1].set_title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test[:, 0].min(), X_test[:, 0].max(), X_test[:, 1].min(), X_test[:, 1].max())\n",
    "print(X_train[:, 0].min(), X_train[:, 0].max(), X_train[:, 1].min(), X_train[:, 1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 2, 400)\n",
    "y = np.linspace(-1.2, 1.6, 400)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "X = np.hstack([xx.reshape(-1, 1), yy.reshape(-1, 1)])\n",
    "extent = [x.min(), x.max(), y.min(), y.max()]\n",
    "ts = np.linspace(0, 1, 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros((n_models, *xx.shape))\n",
    "Z_mode = np.zeros((n_models, *xx.shape))\n",
    "Z_pert = np.zeros((n_models, *xx.shape))\n",
    "for i in tqdm(range(n_models)):\n",
    "    Z[i] = models[i](torch.FloatTensor(X)).detach().numpy()[:, 1].reshape(xx.shape)\n",
    "    Z_mode[i] = mode_models[i].compute_logits(X, TabularModel, ts).mean(axis=0)[:, 1].reshape(xx.shape)\n",
    "    Z_pert[i] = pert_models[i](torch.FloatTensor(X)).detach().numpy().mean(axis=0)[:, 1].reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of average prediction\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5), dpi=150)\n",
    "titles = ['Standard', 'Perturbed', 'Bezier']\n",
    "for i, z in enumerate([Z, Z_pert, Z_mode]):\n",
    "    im = ax[i].imshow(z.mean(axis=0), extent=extent, origin='lower', cmap='RdYlBu', alpha=0.8)\n",
    "    fig.colorbar(im, fraction=0.035)\n",
    "    # Scatter test data, dark red for class 0, dark blue for class 1\n",
    "\n",
    "\n",
    "    ax[i].scatter(testset.data[:, 0], testset.data[:, 1], c=testset.labels, s=4, cmap='hot', alpha=0.5)\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['binary', 'gist_yarg', 'gist_gray', 'gray', 'bone',\n",
    "        'pink', 'spring', 'summer', 'autumn', 'winter', 'cool',\n",
    "        'Wistia', 'hot', 'afmhot', 'gist_heat', 'copper']\n",
    "for col in cols:\n",
    "    # Plot heatmap of 5 models predictions\n",
    "        model_idx = [94,133,64,161]#np.random.choice(n_models, 5, replace=False)\n",
    "        s = 4\n",
    "        back_alpha = 0.9\n",
    "        cmap = col\n",
    "\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(10,6), dpi=150)\n",
    "        fig.subplots_adjust(right=0.8)\n",
    "        plt.subplots_adjust(wspace=0.035, hspace=0.1)\n",
    "        for i, idx in enumerate(model_idx):\n",
    "                zi = models[idx](torch.FloatTensor(X)).detach().numpy()[:, 1].reshape(xx.shape)\n",
    "                im = ax[i//2,i%2].imshow(zi, extent=extent, origin='lower', cmap=cmap, alpha=back_alpha)\n",
    "                ax[i//2,i%2].scatter(testset.data[:, 0], testset.data[:, 1], cmap='hot_r',  c=testset.labels, alpha=0.9, s=s)\n",
    "                ax[i//2,i%2].set_xticks([])\n",
    "                ax[i//2,i%2].set_yticks([])\n",
    "        cbar_ax = fig.add_axes([0.815, 0.11, 0.02, 0.77])  # x, y, width, height\n",
    "        fig.colorbar(im, cax=cbar_ax)\n",
    "        for t in cbar_ax.get_yticklabels():\n",
    "                t.set_fontsize(16)\n",
    "        plt.suptitle('Model Variation due to Random Seed', fontsize=18, y=0.93, x=0.465)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors, colormaps\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "# Get red/blue colormap from matplotlib\n",
    "cmap = colormaps['RdYlBu']\n",
    "light_red = cmap(0.2)  # Adjust this value to get the desired shade of light red\n",
    "yellow = cmap(0.5)  # This value is fixed\n",
    "light_blue = cmap(0.8)  # Adjust this value to get the desired shade of light blue\n",
    "\n",
    "# Create a custom colormap with the desired range\n",
    "cols = [light_red, yellow, light_blue][::-1]  # Color list: [light_red, white, light_blue]\n",
    "custom_cmap = LinearSegmentedColormap.from_list('custom_RdYlBu', cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of 5 models predictions\n",
    "model_idx = [94,133,64,161]#np.random.choice(n_models, 5, replace=False)\n",
    "s, alpha = 6, 0.7\n",
    "back_alpha = 1\n",
    "cmap = custom_cmap#'RdYlBu_r'\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10,6), dpi=200)\n",
    "fig.subplots_adjust(right=0.8)\n",
    "plt.subplots_adjust(wspace=0.035, hspace=0.06)\n",
    "for i, idx in enumerate(model_idx):\n",
    "    zi = models[idx](torch.FloatTensor(X)).detach().numpy()[:, 1].reshape(xx.shape)\n",
    "    im = ax[i//2,i%2].imshow(zi**0.3, extent=extent, origin='lower', cmap=cmap, alpha=back_alpha)\n",
    "    ax[i//2,i%2].scatter(testset.data[:, 0], testset.data[:, 1], cmap='RdYlBu',  c=1-testset.labels, alpha=alpha, s=s)\n",
    "    ax[i//2,i%2].set_xticks([])\n",
    "    ax[i//2,i%2].set_yticks([])\n",
    "# Remove right and bottom border for ax[0,0]\n",
    "ax[0,0].spines['right'].set_visible(False)\n",
    "ax[0,0].spines['bottom'].set_visible(False)\n",
    "ax[0,1].spines['left'].set_visible(False)\n",
    "ax[0,1].spines['bottom'].set_visible(False)\n",
    "cbar_ax = fig.add_axes([0.815, 0.11, 0.02, 0.77])  # x, y, width, height\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "for t in cbar_ax.get_yticklabels():\n",
    "     t.set_fontsize(16)\n",
    "plt.suptitle('Model Variation within the Underspecification Set', fontsize=19, y=0.935, x=0.465)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of 5 models predictions\n",
    "model_idx = [94,133,64,161]#np.random.choice(n_models, 5, replace=False)\n",
    "s = 6\n",
    "back_alpha = 1.0\n",
    "cmap = custom_cmap#'RdYlBu'\n",
    "\n",
    "fig, ax = plt.subplots(1, len(model_idx), figsize=(len(model_idx)*4, 5))\n",
    "for i, idx in enumerate(model_idx):\n",
    "    zi = models[idx](torch.FloatTensor(X)).detach().numpy()[:, 1].reshape(xx.shape)\n",
    "    im = ax[i].imshow(zi, extent=extent, origin='lower', cmap=cmap, alpha=back_alpha)\n",
    "    fig.colorbar(im, fraction=0.035)\n",
    "    ax[i].scatter(testset.data[:, 0], testset.data[:, 1], cmap='hot_r',  c=testset.labels, alpha=0.5, s=s)\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, len(model_idx), figsize=(len(model_idx)*4, 5))\n",
    "for i, idx in enumerate(model_idx):\n",
    "    zi = pert_models[i](torch.FloatTensor(X)).detach().numpy()[:, :, 1].mean(axis=0).reshape(xx.shape)\n",
    "    im = ax[i].imshow(zi, extent=extent, origin='lower', cmap=cmap, alpha=back_alpha)\n",
    "    fig.colorbar(im, fraction=0.035)\n",
    "    ax[i].scatter(testset.data[:, 0], testset.data[:, 1],  cmap='hot_r', c=testset.labels, alpha=0.5, s=s)\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, len(model_idx), figsize=(len(model_idx)*4, 5))\n",
    "for i, idx in enumerate(model_idx):\n",
    "    zi = mode_models[i].compute_logits(X, TabularModel, ts)[:, :, 1].mean(axis=0).reshape(xx.shape)\n",
    "    im = ax[i].imshow(zi, extent=extent, origin='lower', cmap=cmap, alpha=back_alpha)\n",
    "    fig.colorbar(im, fraction=0.035)\n",
    "    ax[i].scatter(testset.data[:, 0], testset.data[:, 1], c=testset.labels, cmap='hot_r', alpha=0.5, s=s)\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grads(method, idx):\n",
    "    if method == 'average':\n",
    "        grads = models[idx].compute_gradients(torch.FloatTensor(X), return_numpy=True)\n",
    "    elif method == 'perturb':\n",
    "        grads = pert_models[idx].compute_gradients(X, mean=True)\n",
    "    elif method == 'mode connect':\n",
    "        grads = mode_models[idx].compute_gradients(X, TabularModel, ts).mean(axis=0)\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['average', 'perturb', 'mode connect']\n",
    "grads_grid = np.zeros((len(methods), n_models, X.shape[0], 2))\n",
    "from datasets.tabular import TabularModel\n",
    "for i, method in enumerate(methods):\n",
    "    for j in tqdm(range(n_models)):\n",
    "        # Compute gradients\n",
    "        grads_grid[i,j] = get_grads(method, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ensemble_sizes = [1, 2, 4, 6, 8, 10]\n",
    "n_trials = 20\n",
    "k = 1\n",
    "\n",
    "# Compute statistics\n",
    "e_grads_grid = np.zeros((len(methods), len(ensemble_sizes), n_trials, X.shape[0], 2))\n",
    "angles_grid = np.zeros((len(methods), len(ensemble_sizes), X.shape[0]))\n",
    "cosines_grid = np.zeros((len(methods), len(ensemble_sizes), X.shape[0]))\n",
    "# topk = np.zeros((len(methods), len(ensemble_sizes), n_trials, X.shape[0], k))\n",
    "# signs = np.zeros((len(methods), len(ensemble_sizes), n_trials, X.shape[0], k), dtype=int)\n",
    "# sa = np.zeros((len(methods), len(ensemble_sizes), X.shape[0]))\n",
    "\n",
    "from datasets.tabular import TabularModel\n",
    "for i, method in enumerate(methods):\n",
    "    for j, ensemble_size in enumerate(tqdm(ensemble_sizes)):\n",
    "        e_size = ensemble_size//2 if method == 'mode connect' else ensemble_size\n",
    "        e_grads_grid[i,j] = grads_grid[i, :n_trials*e_size].reshape(n_trials, e_size, *X.shape).mean(axis=1)\n",
    "        angles_grid[i,j] = average_pairwise_score_grad(e_grads_grid[i,j], angle_diff)\n",
    "        cosines_grid[i,j] = average_pairwise_score_grad(e_grads_grid[i,j], cosine_similarity)\n",
    "        # topk[i,j], signs[i,j] = get_top_k(k, e_grads[i,j], return_sign=True)\n",
    "        # sa[i,j] = average_pairwise_score(topk[i,j], signs[i,j], top_k_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_methods(sim, idx, vmin, vmax, sep, scale=2.5, cmap='RdYlGn_r'):\n",
    "    v = np.arange(vmin, vmax, sep)\n",
    "    for j, method in enumerate(methods):\n",
    "        fig, ax = plt.subplots(1, len(ensemble_sizes), figsize=(4*len(ensemble_sizes), 3), dpi=150)\n",
    "        plt.subplots_adjust(wspace=0.2)\n",
    "        for i, ensemble_size in enumerate(ensemble_sizes):\n",
    "            Z = sims[sim][j,i].reshape(xx.shape)\n",
    "            im = ax[i].imshow(Z, vmin=vmin, vmax=vmax, extent=extent, origin='lower', cmap=cmap)\n",
    "            fig.colorbar(im, ax=ax[i], fraction=0.035, boundaries=v)\n",
    "            pg = e_grads_grid[j, i, :, idx]\n",
    "            norm = np.linalg.norm(pg, axis=1)\n",
    "            # Convert norm to range 0.5, 1\n",
    "            norm = (norm - norm.min()) / (norm.max() - norm.min()) + 0.5\n",
    "            pg = pg / np.linalg.norm(pg, axis=1, keepdims=True)\n",
    "            pg = pg * norm[:, None]\n",
    "            ax[i].quiver(np.repeat(X[idx,0], n_trials), np.repeat(X[idx,1], n_trials),\n",
    "                        pg[:,0], pg[:, 1], angles='xy', scale_units='xy', scale=scale, color='black')\n",
    "            ax[i].set_title(f'Ensemble size: {ensemble_size}')\n",
    "            ax[i].set_xticks([]); ax[i].set_yticks([])\n",
    "        plt.suptitle(f'Average pairwise {sim} difference ({titles[j]})')\n",
    "        plt.show()\n",
    "\n",
    "titles = ['Average', 'Perturb', 'Mode Connect']\n",
    "sims = {'angle difference': angles_grid,\n",
    "        'cosine similarity': cosines_grid,\n",
    "        'sign agreement': sa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(angles_grid[0,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_sizes_plot = []\n",
    "fig, ax = plt.subplots(1, len(ensemble_sizes), figsize=(4*len(ensemble_sizes), 3), dpi=150)\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "for i, ensemble_size in enumerate(ensemble_sizes):\n",
    "    Z = sims[sim][j,i].reshape(xx.shape)\n",
    "    im = ax[i].imshow(Z, vmin=vmin, vmax=vmax, extent=extent, origin='lower', cmap=cmap)\n",
    "    fig.colorbar(im, ax=ax[i], fraction=0.035, boundaries=v)\n",
    "    pg = e_grads_grid[j, i, :, idx]\n",
    "    norm = np.linalg.norm(pg, axis=1)\n",
    "    # Convert norm to range 0.5, 1\n",
    "    norm = (norm - norm.min()) / (norm.max() - norm.min()) + 0.5\n",
    "    pg = pg / np.linalg.norm(pg, axis=1, keepdims=True)\n",
    "    pg = pg * norm[:, None]\n",
    "    ax[i].quiver(np.repeat(X[idx,0], n_trials), np.repeat(X[idx,1], n_trials),\n",
    "                pg[:,0], pg[:, 1], angles='xy', scale_units='xy', scale=scale, color='black')\n",
    "    ax[i].set_title(f'Ensemble size: {ensemble_size}')\n",
    "    ax[i].set_xticks([]); ax[i].set_yticks([])\n",
    "plt.suptitle(f'Average pairwise {sim} difference ({titles[j]})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(angles_grid[0,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = right_idx[3]\n",
    "vmin, vmax = 0, 91\n",
    "sep = 10\n",
    "z = angles_grid[0,0].reshape(xx.shape)\n",
    "pg = e_grads_grid[0,0, :, idx]\n",
    "plt.figure(figsize=(6,6), dpi=100)\n",
    "plt.imshow(z, vmin=vmin, vmax=vmax, extent=extent, origin='lower', cmap='RdYlBu_r')\n",
    "plt.colorbar(fraction=0.0314, boundaries=np.arange(vmin, vmax, sep))\n",
    "plt.quiver(np.repeat(X[idx,0], n_trials), np.repeat(X[idx,1], n_trials),\n",
    "            pg[:,0], pg[:, 1], angles='xy', scale_units='xy', scale=8, color='black', alpha=0.75)\n",
    "plt.title('Angular Difference between Ensemble Gradients', fontweight='bold')\n",
    "plt.xticks([]); plt.yticks([])\n",
    "# no plot border\n",
    "# plt.gca().spines['right'].set_visible(False)\n",
    "# plt.gca().spines['top'].set_visible(False)\n",
    "# plt.gca().spines['left'].set_visible(False)\n",
    "# plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.argsort(angles_grid[0,0])[-20:][::-1]\n",
    "idxs\n",
    "left_idx = idxs[idxs % 400 < 201]\n",
    "right_idx = idxs[idxs % 400 > 200]\n",
    "left_idx, right_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = left_idx[1]\n",
    "vmin, vmax, sep = 0, 91, 10\n",
    "v = np.arange(vmin, vmax, sep)\n",
    "ensemble_size = 4\n",
    "e_idx = ensemble_sizes.index(ensemble_size)\n",
    "ijs = [[0,0], [0,e_idx], [1,e_idx], [2,e_idx]]  # (method, ensemble) index pairs e.g. mode connect, size 2 would be (2,1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(6*len(ijs), 6), dpi=400)\n",
    "plt.subplots_adjust(wspace=0.15)\n",
    "\n",
    "method_titles = ['Vanilla', 'Perturbed', 'Connected']\n",
    "n_grads_plot = 15\n",
    "\n",
    "for i, (m_i, e_i) in enumerate(ijs):\n",
    "    zi = angles_grid[m_i, e_i].reshape(xx.shape)\n",
    "    im = ax[i].imshow(zi, vmin=vmin, vmax=vmax, extent=extent, origin='lower', cmap='RdYlBu_r')\n",
    "    fig.colorbar(im, ax=ax[i], fraction=0.0425, boundaries=v)\n",
    "    pg = e_grads_grid[m_i, e_i, :, idx]\n",
    "    norm = np.linalg.norm(pg, axis=1)\n",
    "    # Convert norm to range 0.5, 1\n",
    "    norm = (norm - norm.min()) / (norm.max() - norm.min()) + 0.5\n",
    "    pg = pg / np.linalg.norm(pg, axis=1, keepdims=True)\n",
    "    pg = pg * norm[:, None]\n",
    "    ax[i].quiver(np.repeat(X[idx,0], n_trials), np.repeat(X[idx,1], n_trials),\n",
    "                pg[:,0], pg[:, 1], angles='xy', scale_units='xy', scale=1, color='black', alpha=0.7-0.1*(i>0))\n",
    "    if e_i == 0:\n",
    "        ax[i].set_title('Constituent Models', fontsize=19)\n",
    "    else:\n",
    "        ax[i].set_title(f'{method_titles[m_i]} Ensembles', fontsize=19)\n",
    "    ax[i].set_xticks([]); ax[i].set_yticks([])\n",
    "# plt.suptitle(f'Average pairwise angular difference between gradients (ensembles of size {ensemble_size})',\n",
    "#              y=0.84, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = left_idx[0]\n",
    "vmin, vmax, sep = 0, 91, 10\n",
    "v = np.arange(vmin, vmax, sep)\n",
    "ensemble_size = 4\n",
    "e_idx = ensemble_sizes.index(ensemble_size)\n",
    "ijs = [[0,e_idx], [1,e_idx], [2,e_idx]]  # (method, ensemble) index pairs e.g. mode connect, size 2 would be (2,1)\n",
    "\n",
    "fig, ax = plt.subplots(1, len(ijs), figsize=(6*len(ijs), 6), dpi=200)\n",
    "plt.subplots_adjust(wspace=0.15)\n",
    "\n",
    "method_titles = ['Vanilla', 'Weight Perturbation', 'Mode Connectivity']\n",
    "\n",
    "for i, (m_i, e_i) in enumerate(ijs):\n",
    "    zi = angles_grid[m_i, e_i].reshape(xx.shape)\n",
    "    im = ax[i].imshow(zi, vmin=vmin, vmax=vmax, extent=extent, origin='lower', cmap='RdYlBu_r')\n",
    "    fig.colorbar(im, ax=ax[i], fraction=0.0313, boundaries=v)\n",
    "    pg = e_grads_grid[m_i, e_i, :, idx]\n",
    "    norm = np.linalg.norm(pg, axis=1)\n",
    "    # Convert norm to range 0.5, 1\n",
    "    norm = (norm - norm.min()) / (norm.max() - norm.min()) + 0.5\n",
    "    pg = pg / np.linalg.norm(pg, axis=1, keepdims=True)\n",
    "    pg = pg * norm[:, None]\n",
    "    ax[i].quiver(np.repeat(X[idx,0], n_trials), np.repeat(X[idx,1], n_trials),\n",
    "                pg[:,0], pg[:, 1], angles='xy', scale_units='xy', scale=1, color='black')\n",
    "    ax[i].set_title(f'{method_titles[m_i]} Ensembles', fontsize=14)\n",
    "    ax[i].set_xticks([]); ax[i].set_yticks([])\n",
    "# plt.suptitle(f'Average pairwise angular difference between gradients (ensembles of size {ensemble_size})',\n",
    "#              y=0.84, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of angles\n",
    "idx = right_idx[0]\n",
    "vmin, vmax = 0, 91\n",
    "sep = 5\n",
    "plot_methods('angle difference', idx, vmin, vmax, sep, scale=0.9, cmap='RdYlBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of cosine similarities\n",
    "idx = np.argmin(cosines[0,0])\n",
    "vmin, vmax = 0.35, 0.51\n",
    "sep = 0.05\n",
    "plot_methods('cosine similarity', idx, vmin, vmax, sep, scale=5, cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of sign agreements\n",
    "idx = np.argmin(sa[0,0])\n",
    "vmin, vmax = 0.4, 1.01\n",
    "sep = 0.1\n",
    "plot_methods('sign agreement', idx, vmin, vmax, sep, scale=5, cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of angles\n",
    "titles = ['Original', 'Perturbed']\n",
    "idx = np.argmin(sa[0])\n",
    "sims = [sa, sa_perturb]\n",
    "sim_grads = [e_grads, e_grads_perturb]\n",
    "vmin, vmax = 0.4, 1.01\n",
    "sep = 0.1\n",
    "v = np.arange(vmin, vmax, sep)\n",
    "for j, sim in enumerate(sims):\n",
    "    fig, ax = plt.subplots(1, len(ensemble_sizes), figsize=(4*len(ensemble_sizes), 3), dpi=150)\n",
    "    plt.subplots_adjust(wspace=0.2)\n",
    "    for i, ensemble_size in enumerate(ensemble_sizes):\n",
    "        Z = sim[i].reshape(xx.shape)\n",
    "        im = ax[i].imshow(Z, vmin=vmin, vmax=vmax, extent=extent, origin='lower', cmap='RdYlGn')\n",
    "        fig.colorbar(im, fraction=0.035, boundaries=v)\n",
    "        ax[i].quiver(np.repeat(X[idx,0], n_trials), np.repeat(X[idx,1], n_trials),\n",
    "                     sim_grads[j][i, :, idx, 0], sim_grads[j][i, :, idx, 1],\n",
    "                     angles='xy', scale_units='xy', scale=2.5, color='black')\n",
    "        ax[i].set_title(f'Ensemble size: {ensemble_size}')\n",
    "        ax[i].set_xticks([]); ax[i].set_yticks([])\n",
    "    plt.suptitle(f'Average pairwise cosine similarity ({titles[j]})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(sims), figsize=(6*len(sims), 3), dpi=150)\n",
    "for i, sim in enumerate(sims):\n",
    "    for j, method in enumerate(methods):\n",
    "        q = np.quantile(sims[sim][j], [0.4, 0.5, 0.6], axis=1)\n",
    "        ax[i].plot(ensemble_sizes, q[1], label=titles[j])\n",
    "        ax[i].fill_between(ensemble_sizes, q[0], q[2], alpha=0.2)\n",
    "    ax[i].set_xlabel('Ensemble size')\n",
    "    ax[i].set_title(f'Average pairwise {sim}')\n",
    "    ax[i].legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of sa\n",
    "idx = 3144\n",
    "Z = angles.reshape(xx.shape)\n",
    "plt.imshow(Z, extent=[-2, 3, -1.5, 2], origin='lower', cmap='RdBu')\n",
    "plt.colorbar()\n",
    "plt.scatter(trainset.data[:, 0], trainset.data[:, 1], c=trainset.labels)\n",
    "plt.quiver(np.repeat(X[idx,0], n_models), np.repeat(X[idx,1], n_models), grads[:, idx, 0], grads[:, idx, 1], scale=15, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "tk, s = get_top_k(k, grads, return_sign=True)\n",
    "sa = average_pairwise_score(tk, s, top_k_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of sa\n",
    "Z = sa.reshape(xx.shape)\n",
    "plt.imshow(Z, extent=[-2, 3, -1.5, 2], origin='lower', cmap='RdBu')\n",
    "plt.colorbar()\n",
    "plt.scatter(trainset.data[:, 0], trainset.data[:, 1], c=trainset.labels)\n",
    "plt.quiver(np.repeat(X[idx,0], n_models), np.repeat(X[idx,1], n_models), grads[:, idx, 0], grads[:, idx, 1], scale=15, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modconn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modconn.curves import train_curve\n",
    "from modconn import curves\n",
    "from datasets.tabular import TabularModelCurve\n",
    "layers = datasets.tabular.layers['moons']\n",
    "model_args = [n_features, layers]\n",
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_connect(models, trainloader, lr, epochs, curve_type='polychain', optim='sgd',\n",
    "                 ts=np.linspace(0, 1, 101), disable_tqdm=True, fix_start=False, fix_end=False):\n",
    "    if curve_type == 'polychain':\n",
    "        curve_type = curves.PolyChain\n",
    "    elif curve_type == 'bezier':\n",
    "        curve_type = curves.Bezier\n",
    "    else:\n",
    "        raise ValueError(f'Unknown curve type {curve_type}')\n",
    "    p_curve = curves.train_curve(models=models, trainloader=trainloader,\n",
    "                                 curve_class=TabularModelCurve, curve=curve_type,\n",
    "                                 input_size=model_args[0], hidden_layers=model_args[1],\n",
    "                                 fix_start=fix_start, fix_end=fix_end, optim=optim,\n",
    "                                 lr=lr, epochs=epochs, disable_tqdm=disable_tqdm)\n",
    "    # Compute gradients\n",
    "    p_curve_logits = p_curve.compute_logits(X_test, TabularModel, ts)\n",
    "    p_curve_grads = p_curve.compute_gradients(X_test, TabularModel, ts)\n",
    "    return p_curve, p_curve_logits, p_curve_grads\n",
    "\n",
    "def init_model(idx):\n",
    "    torch.manual_seed(idx)\n",
    "    model = TabularModel(*model_args)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curve_statistics(p_curve, ts=np.linspace(0,1,101)):\n",
    "    # Compute losses\n",
    "    loss_fn = torch.nn.functional.cross_entropy\n",
    "    p_curve_loss = np.zeros(len(ts))\n",
    "    p_curve_loss_tr = np.zeros(len(ts))\n",
    "    p_curve_preds_tr = np.zeros((len(ts), *y_train.shape))\n",
    "    p_curve_grads_tr = np.zeros((len(ts), *X_train.shape))\n",
    "    for i, t in enumerate(ts):\n",
    "        model = p_curve.get_model_from_curve(TabularModel, t=t)\n",
    "        p_curve_loss[i] = loss_fn(model.forward(torch.FloatTensor(X_test)), torch.tensor(y_test)).item()\n",
    "        p_curve_loss_tr[i] = loss_fn(model.forward(torch.FloatTensor(X_train)), torch.tensor(y_train)).item()\n",
    "        p_curve_preds_tr[i] = model.predict(X_train, return_numpy=True)\n",
    "        p_curve_grads_tr[i] = model.compute_gradients(X_train, return_numpy=True)\n",
    "    weight_norms = np.zeros(len(ts))\n",
    "    weight_diffs = np.zeros(len(ts))\n",
    "    model_0 = p_curve.get_model_from_curve(TabularModel, t=0)\n",
    "    for i, t in enumerate(ts):\n",
    "        model_t = p_curve.get_model_from_curve(TabularModel, t=t)\n",
    "        weight_norms[i] = get_weight_norm(model_t.state_dict())\n",
    "        weight_diffs[i] = get_weight_diff(model_t.state_dict(), model_0.state_dict())\n",
    "    return p_curve_loss, p_curve_loss_tr, p_curve_preds_tr, p_curve_grads_tr, weight_norms, weight_diffs\n",
    "\n",
    "def plot_statistics(p_curve_loss, p_curve_loss_tr,\n",
    "                    p_curve_preds, p_curve_preds_tr,\n",
    "                    p_curve_grads, p_curve_grads_tr,\n",
    "                    weight_norms, weight_diffs, ts=np.linspace(0,1,101)):\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(20, 4), dpi=150)\n",
    "    ax[0].plot(ts, p_curve_loss, label='Test')\n",
    "    ax[0].plot(ts, p_curve_loss_tr, label='Train')\n",
    "\n",
    "    ax[1].plot(ts, 100*(p_curve_preds==y_test).mean(axis=1), label='Test')\n",
    "    ax[1].plot(ts, 100*(p_curve_preds_tr==y_train).mean(axis=1), label='Train')\n",
    "\n",
    "    q = np.quantile(np.linalg.norm(p_curve_grads, axis=2), [0.25, 0.5, 0.75], axis=1)\n",
    "    ax[2].plot(ts, q[1], label='Test')\n",
    "    ax[2].fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "    q = np.quantile(np.linalg.norm(p_curve_grads_tr, axis=2), [0.25, 0.5, 0.75], axis=1)\n",
    "    ax[2].plot(ts, q[1], label='Train')\n",
    "    ax[2].fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "\n",
    "    topk, signs = get_top_k(1, p_curve_grads, return_sign=True)\n",
    "    gt_score = ground_truth_score(topk, signs, gt, signs_gt, top_k_sa)\n",
    "    q = np.quantile(gt_score, [0.25, 0.5, 0.75], axis=1)\n",
    "    ax[3].plot(ts, q[1], label='Test')\n",
    "    ax[3].fill_between(ts, q[0], q[2], alpha=0.2)\n",
    "\n",
    "    ax[4].plot(ts, weight_norms, label='Weight Norm')\n",
    "    ax[4].plot(ts, weight_diffs, label='Weight Diff')\n",
    "\n",
    "    titles = ['Loss', 'Accuracy (%)', 'Gradient Norm', 'Ground Truth SA Similarity', 'Weight Norm']\n",
    "    for i in range(5):\n",
    "        ax[i].set_xlabel('t')\n",
    "        ax[i].legend()\n",
    "        ax[i].set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = np.zeros((n_models, X_test.shape[0], 2))\n",
    "for i in tqdm(range(n_models)):\n",
    "    # Compute gradients\n",
    "    grad[i] = models[i].compute_gradients(X_test, return_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt, signs_gt = get_top_k(1, grad.mean(axis=0), return_sign=True)\n",
    "tk, s = get_top_k(1, grad, return_sign=True)\n",
    "orig_sa = average_ground_truth_score(tk, s, gt, signs_gt, top_k_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = linear_weight_interpolation(models[54].state_dict(), models[155].state_dict(), [0, 0.25, 0.5, 0.75, 1.0])\n",
    "curve_models = []\n",
    "for weight in weights:\n",
    "    model = TabularModel(*model_args)\n",
    "    model.load_state_dict(weight)\n",
    "    curve_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from align import align_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(trainset, 32, shuffle=True)\n",
    "model = TabularModel(*model_args)\n",
    "model.state_dict()['network.0.weight'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, 1, 50)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=False)\n",
    "model_0 = models[9]\n",
    "model_1 = models[10]\n",
    "model_a = align_tabular(model_0, model_1, trainloader, model_args)\n",
    "curve_models = [model_a, model_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_weight_norm(model_0), get_weight_norm(model_1), get_weight_norm(model_a))\n",
    "print(get_weight_diff(model_0, model_1), get_weight_diff(model_0, model_a), get_weight_diff(model_a, model_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_curves = 100\n",
    "ts = np.linspace(0, 1, 50)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=False)\n",
    "p_curve_grads = np.zeros((n_curves, len(ts), X_test.shape[0], 2))\n",
    "p_curves = []\n",
    "for i in tqdm(range(n_curves)):\n",
    "    model_0 = models[i*2]\n",
    "    model_1 = models[i*2+1]\n",
    "    model_a = align_tabular(model_0, model_1, trainloader, model_args)\n",
    "    curve_models = [model_a, model_1]\n",
    "    p_curve, p_curve_logits, p_curve_grads[i] = mode_connect(curve_models, trainloader=trainloader, lr=0.1, optim='sgd',\n",
    "                                                        epochs=100, curve_type='bezier', ts=ts,\n",
    "                                                        disable_tqdm=True, fix_start=False, fix_end=True)\n",
    "    p_curves.append(p_curve)\n",
    "    # outputs = get_curve_statistics(p_curve, ts=ts)\n",
    "    # p_curve_loss, p_curve_loss_tr, p_curve_preds_tr, p_curve_grads_tr, weight_norms, weight_diffs = outputs\n",
    "    # plot_statistics(p_curve_loss, p_curve_loss_tr, p_curve_logits.argmax(axis=2), p_curve_preds_tr,\n",
    "    #                 p_curve_grads, p_curve_grads_tr, weight_norms, weight_diffs, ts=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pert_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5858\n",
    "x = X[idx:idx+1]\n",
    "#p_curve = mode_models[8]\n",
    "pg = grads[0,:198,idx].reshape(3, 66, 2).mean(axis=0)\n",
    "pg_mode = np.zeros((n_curves, 2))\n",
    "pg_pert = np.zeros((len(pert_models), 2))\n",
    "for i in tqdm(range(n_curves)):\n",
    "    pg_mode[i] = p_curves[i].compute_gradients(x, TabularModel, ts=np.linspace(0,1,100))[:,0].mean(axis=0)\n",
    "for i in tqdm(range(len(pert_models))):\n",
    "    pg_pert[i] = pert_models[i].compute_gradients(x, mean=True)\n",
    "pg_pert = pg_pert[:198].reshape(3, 66, 2).mean(axis=0)\n",
    "pg_mode = pg_mode[:66]\n",
    "x = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_angle(g):\n",
    "    angs = np.zeros(len(g))\n",
    "    for i in range(len(g)):\n",
    "        angs[i] = np.arctan(g[i,1]/g[i,0])*180/np.pi\n",
    "    return angs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5), dpi=100)\n",
    "method_grads = [pg_mode, pg]\n",
    "ax[0].boxplot([np.linalg.norm(g, axis=1) for g in method_grads],\n",
    "             labels=['Original', 'Mode Connect'])\n",
    "ax[0].set_title('Gradient Norms')\n",
    "for g in method_grads:\n",
    "    ax[1].hist(np.linalg.norm(g, axis=1), bins=30, alpha=0.5)\n",
    "    ax[2].hist(x_angle(g), bins=30, alpha=0.5)\n",
    "ax[0].set_ylabel('Gradient Norm')\n",
    "ax[1].set_ylabel('Count')\n",
    "ax[2].set_ylabel('Count')\n",
    "ax[1].legend(['Original', 'Mode Connect'])\n",
    "ax[2].legend(['Original', 'Mode Connect'])\n",
    "ax[1].set_title('Gradient Norms')\n",
    "ax[2].set_title('Gradient Angles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.shape, pg_mode.shape, pg_pert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_mode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiver_plots([grads[0,:,idx], pg_mode, pg_pert], x, scale=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quiver_plot(pg, x, scale=1.0):\n",
    "    # Plot the gradients in pg as a quiver plot at x\n",
    "    n_grads = pg.shape[0]\n",
    "    plt.quiver(np.repeat(x[0], n_grads),\n",
    "               np.repeat(x[1], n_grads),\n",
    "               pg[:,0], pg[:,1], angles='xy',\n",
    "               scale_units='xy', scale=scale,\n",
    "               color=cmaps['RdYlGn'](np.linspace(0,1,n_grads)))\n",
    "    # start_end_pg_x = [pg[0,0], pg[-1,0]]\n",
    "    # start_end_pg_y = [pg[0,1], pg[-1,1]]\n",
    "    # plt.quiver(np.repeat(x[0], 2),\n",
    "    #            np.repeat(x[1], 2),\n",
    "    #            start_end_pg_x, start_end_pg_y,\n",
    "    #            angles='xy', scale_units='xy',\n",
    "    #            scale=scale, color='black')\n",
    "    mean_pg_x = pg.mean(axis=0)[0]\n",
    "    mean_pg_y = pg.mean(axis=0)[1]\n",
    "    # Dotted quiver\n",
    "    plt.quiver(np.repeat(x[0], 1),\n",
    "                np.repeat(x[1], 1),\n",
    "                mean_pg_x, mean_pg_y,\n",
    "                angles='xy', scale_units='xy',\n",
    "                scale=scale, color='black')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quiver_plots(pgs, x, scale=1.0):\n",
    "    # As above, but for multiple sets of gradients (one per column of plot)\n",
    "    n_cols = len(pgs)\n",
    "    fig, ax = plt.subplots(1, n_cols, figsize=(n_cols*7, 5), dpi=100)\n",
    "    for i, pg in enumerate(pgs):\n",
    "        n_grads = pg.shape[0]\n",
    "        ax[i].quiver(np.repeat(x[0], n_grads),\n",
    "                       np.repeat(x[1], n_grads),\n",
    "                       pg[:,0], pg[:,1], angles='xy',\n",
    "                       scale_units='xy', scale=scale,\n",
    "                       color=cmaps['RdYlGn'](np.linspace(0,1,n_grads)))\n",
    "        mean_pg_x = pg.mean(axis=0)[0]\n",
    "        mean_pg_y = pg.mean(axis=0)[1]\n",
    "        # Dotted quiver\n",
    "        ax[i].quiver(np.repeat(x[0], 1),\n",
    "                        np.repeat(x[1], 1),\n",
    "                        mean_pg_x, mean_pg_y,\n",
    "                        angles='xy', scale_units='xy',\n",
    "                        scale=scale, color='black')\n",
    "        ax[i].set_xlabel('x1')\n",
    "        ax[i].set_ylabel('x2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
